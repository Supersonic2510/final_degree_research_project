{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca6e6a2cf383f5aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T17:15:42.214053Z",
     "start_time": "2024-09-01T17:15:40.134256Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import model and check parameters\n",
    "from ultralytics import YOLO, settings\n",
    "import gc\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a3be177fdd2f122",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T17:15:42.226759Z",
     "start_time": "2024-09-01T17:15:42.223948Z"
    }
   },
   "outputs": [],
   "source": [
    "base_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed754eaafa2dd1d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T17:15:42.710998Z",
     "start_time": "2024-09-01T17:15:42.705006Z"
    }
   },
   "outputs": [],
   "source": [
    "settings.update({\"datasets_dir\": f\"{base_path}/data\"})\n",
    "settings.update({\"runs_dir\": f\"{base_path}/runs\"})\n",
    "settings.update({\"weights_dir\": f\"{base_path}/models\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9f90ec3-b9a1-42b8-baba-c6ded3dab8ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T17:15:43.394652Z",
     "start_time": "2024-09-01T17:15:43.277925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8x summary: 365 layers, 68,229,648 parameters, 0 gradients, 258.5 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(365, 68229648, 0, 258.5472512)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO(os.path.join(base_path, \"models/yolov8x.pt\"))\n",
    "\n",
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f67fd9c0df905eda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T17:15:44.382282Z",
     "start_time": "2024-09-01T17:15:44.312519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing CUDA memory on GPU 0\n",
      "Clearing CUDA memory on GPU 1\n",
      "Clearing CUDA memory on GPU 2\n",
      "Clearing CUDA memory on GPU 3\n",
      "CUDA memory cleared on all GPUs and garbage collection done.\n"
     ]
    }
   ],
   "source": [
    "# Clear cuda memory\n",
    "# Clear CUDA memory and perform garbage collection on all available GPUs\n",
    "def clear_cuda_memory():\n",
    "    # Get the number of available GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    \n",
    "    for i in range(num_gpus):\n",
    "        # Set the device to GPU i\n",
    "        torch.cuda.set_device(i)\n",
    "        print(f\"Clearing CUDA memory on GPU {i}\")\n",
    "        \n",
    "        # Clear CUDA memory on the current GPU\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    # Perform Python garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"CUDA memory cleared on all GPUs and garbage collection done.\")\n",
    "\n",
    "\n",
    "# Call the function to clear memory\n",
    "clear_cuda_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5817cb-7f88-419f-b577-6470c869ab72",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-01T17:15:59.720980Z"
    },
    "jupyter": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.89 ðŸš€ Python-3.12.4 torch-2.4.0+cu118 CUDA:0 (NVIDIA GeForce RTX 4090, 24208MiB)\n",
      "                                                           CUDA:1 (NVIDIA GeForce RTX 4090, 24210MiB)\n",
      "                                                           CUDA:2 (NVIDIA GeForce RTX 4090, 24210MiB)\n",
      "                                                           CUDA:3 (NVIDIA GeForce RTX 4090, 24210MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/root/models/yolov8x.pt, data=/root//data/yolo/data.yaml, epochs=1000, time=None, patience=100, batch=100, imgsz=640, save=True, save_period=10, cache=False, device=[0, 1, 2, 3], workers=10, project=results/, name=500e full dataset xl4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=results/500e full dataset xl4\n",
      "Overriding model.yaml nc=80 with nc=401\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   9104131  ultralytics.nn.modules.head.Detect           [401, [320, 640, 640]]        \n",
      "Model summary: 365 layers, 68,538,771 parameters, 68,538,755 gradients, 260.3 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mDDP:\u001b[0m debug command /root/.pyenv/versions/3.12.4/bin/python3.12 -m torch.distributed.run --nproc_per_node 4 --master_port 55043 /root/.config/Ultralytics/DDP/_temp_zsz72avq140656920280864.py\n",
      "Ultralytics YOLOv8.2.89 ðŸš€ Python-3.12.4 torch-2.4.0+cu118 CUDA:0 (NVIDIA GeForce RTX 4090, 24208MiB)\n",
      "                                                           CUDA:1 (NVIDIA GeForce RTX 4090, 24210MiB)\n",
      "                                                           CUDA:2 (NVIDIA GeForce RTX 4090, 24210MiB)\n",
      "                                                           CUDA:3 (NVIDIA GeForce RTX 4090, 24210MiB)\n",
      "Overriding model.yaml nc=80 with nc=401\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /root/data/yolo/train/labels... 39138 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39138/39138 [00:41<00:00, 947.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /root/data/yolo/train/images/1tkB9b98vlipJY4KDEcFjQ.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /root/data/yolo/train/images/AWaOIu70sakf61XU6YC2gA.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /root/data/yolo/train/images/Kt74oD71xjz0Lg47cApFpQ.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /root/data/yolo/train/images/UyY2j_cpHDsY-uQp6hrymg.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /root/data/yolo/train/images/fV0Qr5mN-Ivx-GoUa6UyHA.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /root/data/yolo/train/images/k9gRkG-7xHmTjehkOxCIuw.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /root/data/yolo/train/images/s3k4rk3b9G-0xQEdrP0GLw.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /root/data/yolo/train/images/xSWL6Df98XHSTZqE5juUxA.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /root/data/yolo/train/images/xlnVW3BZ-8NqoUrlXgMUFA.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /root/data/yolo/train/images/ysCtrIHLBIrvjIU0pz6cqw.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /root/data/yolo/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /root/data/yolo/val/labels.cache... 5288 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5288/5288 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to results/500e full dataset xl4/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.00078125), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 40 dataloader workers\n",
      "Logging results to \u001b[1mresults/500e full dataset xl4\u001b[0m\n",
      "Starting training for 1000 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     1/1000      21.1G      1.993      5.985     0.9846         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:37<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:32<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744      0.295     0.0502     0.0227     0.0115\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     2/1000      20.6G       1.93      3.655     0.9792         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:36<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744      0.217      0.116     0.0741     0.0368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     3/1000      20.7G       1.99      2.957      1.006         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:35<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744       0.25     0.0927     0.0658     0.0323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     4/1000      20.7G      1.979      2.736      1.006         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:35<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744      0.301      0.124      0.103     0.0508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     5/1000      20.6G       1.96      2.496     0.9902         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:34<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744      0.355      0.131      0.122      0.061\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     6/1000      20.6G      1.917      2.335     0.9887         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:34<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744      0.391      0.153      0.142     0.0692\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     7/1000      20.6G      1.906      2.237      0.983         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:33<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744      0.394      0.155      0.146     0.0712\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     8/1000      20.6G      1.898      2.158     0.9827         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:33<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744      0.414      0.167      0.159     0.0791\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     9/1000      20.7G      1.891       2.12     0.9767         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:33<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744      0.441      0.179      0.174     0.0827\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    10/1000      20.7G      1.855      2.041     0.9757         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:33<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744      0.453      0.179       0.18     0.0865\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    11/1000      20.6G      1.872      2.019     0.9736         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:34<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744      0.463       0.19      0.187     0.0893\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    12/1000      20.7G      1.855      1.995      0.972         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:34<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744      0.466      0.192      0.191     0.0907\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    13/1000      20.9G      1.858      1.964     0.9694         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:33<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744      0.467      0.196      0.194     0.0931\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    14/1000      20.9G      1.842      1.929     0.9645         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:33<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744       0.48        0.2      0.199     0.0959\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    15/1000      20.7G      1.843      1.895     0.9692         76        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:33<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744      0.489      0.202      0.203     0.0964\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    16/1000      20.7G      1.821      1.874     0.9629         57        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:32<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744        0.5      0.206      0.207     0.0984\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    17/1000      20.7G      1.825       1.86     0.9631         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:32<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744      0.512      0.208      0.211     0.0995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    18/1000      20.6G      1.835      1.871     0.9617         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:32<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744      0.496       0.21      0.211      0.101\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    19/1000      20.7G      1.825      1.845     0.9636         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:32<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744      0.498      0.212      0.213      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    20/1000      20.6G       1.83      1.837     0.9628         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:31<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106/106 [00:31<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5288      25744      0.508      0.216      0.217      0.104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    21/1000      20.7G      1.831      1.834     0.9613         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [03:31<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 82/106 [00:24<00:07,  3.23it/s]"
     ]
    }
   ],
   "source": [
    "project = \"results/\"\n",
    "experiment = \"500e full dataset xl\"\n",
    "dataset = \"/data/yolo/data.yaml\"\n",
    "\n",
    "# 12h Train, in GPU 0 -> device=0\n",
    "# On multiple devices use [0, 1, n]\n",
    "results = model.train(\n",
    "    data=f\"{base_path}/{dataset}\",\n",
    "    seed=42,\n",
    "    epochs=1000,\n",
    "    imgsz=640,\n",
    "    device=[0, 1, 2, 3],\n",
    "    batch=100,\n",
    "    workers=10,\n",
    "    val=True,\n",
    "    plots=True,\n",
    "    save=True,\n",
    "    save_period=10,\n",
    "    resume=False,\n",
    "    project=project,\n",
    "    name=experiment,\n",
    "    fraction=1.0,\n",
    "    cache=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce3b68-8b22-460e-afb0-1f792353fe3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c2d4cb-2633-4c36-bb33-d3b0ab3b34f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c988069-d24a-47c5-9bdc-d29843a2c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model = YOLO(os.path.join(base_path, \"models/best.pt\"))\n",
    "\n",
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2317331bb3dbcbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid export format='pytorch'. Valid formats are ('torchscript', 'onnx', 'openvino', 'engine', 'coreml', 'saved_model', 'pb', 'tflite', 'edgetpu', 'tfjs', 'paddle', 'ncnn')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save model as pytorch format\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpytorch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/ultralytics/engine/model.py:747\u001b[0m, in \u001b[0;36mModel.export\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m custom \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimgsz\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimgsz\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    745\u001b[0m }  \u001b[38;5;66;03m# method defaults\u001b[39;00m\n\u001b[1;32m    746\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[0;32m--> 747\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExporter\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/ultralytics/engine/exporter.py:185\u001b[0m, in \u001b[0;36mExporter.__call__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    183\u001b[0m flags \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;241m==\u001b[39m fmt \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m fmts]\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msum\u001b[39m(flags) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid export format=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfmt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Valid formats are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfmts\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    186\u001b[0m jit, onnx, xml, engine, coreml, saved_model, pb, tflite, edgetpu, tfjs, paddle, ncnn \u001b[38;5;241m=\u001b[39m flags  \u001b[38;5;66;03m# export booleans\u001b[39;00m\n\u001b[1;32m    187\u001b[0m is_tf_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m((saved_model, pb, tflite, edgetpu, tfjs))\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid export format='pytorch'. Valid formats are ('torchscript', 'onnx', 'openvino', 'engine', 'coreml', 'saved_model', 'pb', 'tflite', 'edgetpu', 'tfjs', 'paddle', 'ncnn')"
     ]
    }
   ],
   "source": [
    "# Save model as pytorch format\n",
    "model.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ade59c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.89 ðŸš€ Python-3.12.4 torch-2.4.0+cu118 CPU (AMD EPYC 7742 64-Core Processor)\n",
      "Model summary (fused): 268 layers, 68,509,731 parameters, 0 gradients, 259.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'results/500e full dataset xl4/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 405, 8400) (131.2 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0', 'onnxslim>=0.1.31', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnx>=1.12.0\n",
      "  Downloading onnx-1.16.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting onnxslim>=0.1.31\n",
      "  Downloading onnxslim-0.1.33-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting onnxruntime-gpu\n",
      "  Downloading onnxruntime_gpu-1.19.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in ./.pyenv/versions/3.12.4/lib/python3.12/site-packages (from onnx>=1.12.0) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in ./.pyenv/versions/3.12.4/lib/python3.12/site-packages (from onnx>=1.12.0) (5.28.0)\n",
      "Requirement already satisfied: sympy in ./.pyenv/versions/3.12.4/lib/python3.12/site-packages (from onnxslim>=0.1.31) (1.13.2)\n",
      "Requirement already satisfied: packaging in ./.pyenv/versions/3.12.4/lib/python3.12/site-packages (from onnxslim>=0.1.31) (24.1)\n",
      "Collecting coloredlogs (from onnxruntime-gpu)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime-gpu)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.pyenv/versions/3.12.4/lib/python3.12/site-packages (from sympy->onnxslim>=0.1.31) (1.3.0)\n",
      "Downloading onnx-1.16.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnxslim-0.1.33-py3-none-any.whl (140 kB)\n",
      "Downloading onnxruntime_gpu-1.19.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (226.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m226.2/226.2 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Installing collected packages: flatbuffers, onnx, humanfriendly, onnxslim, coloredlogs, onnxruntime-gpu\n",
      "Successfully installed coloredlogs-15.0.1 flatbuffers-24.3.25 humanfriendly-10.0 onnx-1.16.2 onnxruntime-gpu-1.19.2 onnxslim-0.1.33\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 14.0s, installed 3 packages: ['onnx>=1.12.0', 'onnxslim>=0.1.31', 'onnxruntime-gpu']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.2 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.33...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 41.0s, saved as 'results/500e full dataset xl4/weights/best.onnx' (261.5 MB)\n",
      "\n",
      "Export complete (44.2s)\n",
      "Results saved to \u001b[1m/root/results/500e full dataset xl4/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=results/500e full dataset xl4/weights/best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=results/500e full dataset xl4/weights/best.onnx imgsz=640 data=/root//data/yolo/data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'results/500e full dataset xl4/weights/best.onnx'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model as onnx format\n",
    "model.export(format='onnx', imgsz=640, dynamic=True, simplify=True, batch=1, half=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4f2b20f-d313-4e22-8afd-179ca408fe61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ TensorRT requires GPU export, automatically assigning device=0\n",
      "Ultralytics YOLOv8.2.89 ðŸš€ Python-3.12.4 torch-2.4.0+cu118 CUDA:0 (NVIDIA GeForce RTX 4090, 24208MiB)\n",
      "Model summary (fused): 268 layers, 68,509,731 parameters, 0 gradients, 259.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'results/500e full dataset xl4/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 405, 8400) (131.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.2 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.33...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 28.8s, saved as 'results/500e full dataset xl4/weights/best.onnx' (261.5 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['tensorrt>7.0.0,<=10.1.0'] not found, attempting AutoUpdate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorrt<=10.1.0,>7.0.0\n",
      "  Downloading tensorrt-10.1.0.tar.gz (16 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting tensorrt-cu12 (from tensorrt<=10.1.0,>7.0.0)\n",
      "  Downloading tensorrt-cu12-10.4.0.tar.gz (18 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: tensorrt, tensorrt-cu12\n",
      "  Building wheel for tensorrt (pyproject.toml): started\n",
      "  Building wheel for tensorrt (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for tensorrt: filename=tensorrt-10.1.0-py2.py3-none-any.whl size=16336 sha256=da18647b824fa7ff6188ec55390a19fcca6d60b13aefb6311cb3c01ebb316976\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dchzavl4/wheels/6c/fc/c4/7e30345c05db37c229e8c91c5e3de381dc2ea9707106d60519\n",
      "  Building wheel for tensorrt-cu12 (pyproject.toml): started\n",
      "  Building wheel for tensorrt-cu12 (pyproject.toml): still running...\n",
      "  Building wheel for tensorrt-cu12 (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for tensorrt-cu12: filename=tensorrt_cu12-10.4.0-py2.py3-none-any.whl size=17556 sha256=5da7e335883167f5e4a389cab5815908f4385b84f632efc94022a485f66f3204\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dchzavl4/wheels/c7/26/58/e96e3a124bd7997358b6a8b55bcfaeefd25dac4b9669a15872\n",
      "Successfully built tensorrt tensorrt-cu12\n",
      "Installing collected packages: tensorrt-cu12, tensorrt\n",
      "Successfully installed tensorrt-10.1.0 tensorrt-cu12-10.4.0\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 97.3s, installed 1 package: ['tensorrt>7.0.0,<=10.1.0']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.4.0...\n",
      "[09/09/2024-07:26:01] [TRT] [I] [MemUsageChange] Init CUDA: CPU +12, GPU +0, now: CPU 3229, GPU 401 (MiB)\n",
      "[09/09/2024-07:26:03] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +2235, GPU +428, now: CPU 5619, GPU 829 (MiB)\n",
      "[09/09/2024-07:26:03] [TRT] [I] ----------------------------------------------------------------\n",
      "[09/09/2024-07:26:03] [TRT] [I] Input filename:   results/500e full dataset xl4/weights/best.onnx\n",
      "[09/09/2024-07:26:03] [TRT] [I] ONNX IR version:  0.0.10\n",
      "[09/09/2024-07:26:03] [TRT] [I] Opset version:    19\n",
      "[09/09/2024-07:26:03] [TRT] [I] Producer name:    pytorch\n",
      "[09/09/2024-07:26:03] [TRT] [I] Producer version: 2.4.0\n",
      "[09/09/2024-07:26:03] [TRT] [I] Domain:           \n",
      "[09/09/2024-07:26:03] [TRT] [I] Model version:    0\n",
      "[09/09/2024-07:26:03] [TRT] [I] Doc string:       \n",
      "[09/09/2024-07:26:03] [TRT] [I] ----------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(-1, 3, -1, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(-1, 405, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m WARNING âš ï¸ 'dynamic=True' model requires max batch size, i.e. 'batch=16'\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export failure âŒ 128.5s: set_shape(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: tensorrt_bindings.tensorrt.IOptimizationProfile, input: str, min: tensorrt_bindings.tensorrt.Dims, opt: tensorrt_bindings.tensorrt.Dims, max: tensorrt_bindings.tensorrt.Dims) -> None\n",
      "\n",
      "Invoked with: <tensorrt_bindings.tensorrt.IOptimizationProfile object at 0x7fed0e31a070>, 'images'; kwargs: min=(1, 3, 32, 32), opt=torch.Size([1, 3, 640, 640]), max=(1, 3, 2560.0, 2560.0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "set_shape(): incompatible function arguments. The following argument types are supported:\n    1. (self: tensorrt_bindings.tensorrt.IOptimizationProfile, input: str, min: tensorrt_bindings.tensorrt.Dims, opt: tensorrt_bindings.tensorrt.Dims, max: tensorrt_bindings.tensorrt.Dims) -> None\n\nInvoked with: <tensorrt_bindings.tensorrt.IOptimizationProfile object at 0x7fed0e31a070>, 'images'; kwargs: min=(1, 3, 32, 32), opt=torch.Size([1, 3, 640, 640]), max=(1, 3, 2560.0, 2560.0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save model as onnx format\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mengine\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimplify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhalf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/ultralytics/engine/model.py:747\u001b[0m, in \u001b[0;36mModel.export\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m custom \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimgsz\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimgsz\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    745\u001b[0m }  \u001b[38;5;66;03m# method defaults\u001b[39;00m\n\u001b[1;32m    746\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[0;32m--> 747\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExporter\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/ultralytics/engine/exporter.py:305\u001b[0m, in \u001b[0;36mExporter.__call__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    303\u001b[0m     f[\u001b[38;5;241m0\u001b[39m], _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_torchscript()\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine:  \u001b[38;5;66;03m# TensorRT required before ONNX\u001b[39;00m\n\u001b[0;32m--> 305\u001b[0m     f[\u001b[38;5;241m1\u001b[39m], _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m onnx:  \u001b[38;5;66;03m# ONNX\u001b[39;00m\n\u001b[1;32m    307\u001b[0m     f[\u001b[38;5;241m2\u001b[39m], _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_onnx()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/ultralytics/engine/exporter.py:142\u001b[0m, in \u001b[0;36mtry_export.<locals>.outer_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    141\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m export failure âŒ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mt\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/ultralytics/engine/exporter.py:137\u001b[0m, in \u001b[0;36mtry_export.<locals>.outer_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Profile() \u001b[38;5;28;01mas\u001b[39;00m dt:\n\u001b[0;32m--> 137\u001b[0m         f, model \u001b[38;5;241m=\u001b[39m \u001b[43minner_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m export success âœ… \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mt\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms, saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_size(f)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f, model\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/site-packages/ultralytics/engine/exporter.py:734\u001b[0m, in \u001b[0;36mExporter.export_engine\u001b[0;34m(self, prefix)\u001b[0m\n\u001b[1;32m    732\u001b[0m     max_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m*\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworkspace) \u001b[38;5;241m*\u001b[39m d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m shape[\u001b[38;5;241m2\u001b[39m:]))  \u001b[38;5;66;03m# max input shape\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inp \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[0;32m--> 734\u001b[0m         \u001b[43mprofile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m     config\u001b[38;5;241m.\u001b[39madd_optimization_profile(profile)\n\u001b[1;32m    737\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m building \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINT8\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mint8\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFP\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m16\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mhalf\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m32\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m engine as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: set_shape(): incompatible function arguments. The following argument types are supported:\n    1. (self: tensorrt_bindings.tensorrt.IOptimizationProfile, input: str, min: tensorrt_bindings.tensorrt.Dims, opt: tensorrt_bindings.tensorrt.Dims, max: tensorrt_bindings.tensorrt.Dims) -> None\n\nInvoked with: <tensorrt_bindings.tensorrt.IOptimizationProfile object at 0x7fed0e31a070>, 'images'; kwargs: min=(1, 3, 32, 32), opt=torch.Size([1, 3, 640, 640]), max=(1, 3, 2560.0, 2560.0)"
     ]
    }
   ],
   "source": [
    "# Save model as TensorRT format\n",
    "model.export(\n",
    "    format='engine',       # Export format set to TensorRT\n",
    "    imgsz=640,             # Image size (can be int or tuple for (height, width))\n",
    "    half=False,            # Use full precision (FP32)\n",
    "    dynamic=True,          # Enable dynamic input shapes\n",
    "    simplify=True,         # Simplify ONNX model for performance\n",
    "    workspace=4.0,         # Maximum workspace size in GiB for TensorRT\n",
    "    int8=False,            # Disable INT8 quantization (you can set it to True if you want INT8 optimization)\n",
    "    batch=16               # Max batch size for dynamic model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889becb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model\n",
    "modeltest = YOLO(\"models/best.pt\")\n",
    "metrics = modeltest.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.box.map    # map50-95\n",
    "metrics.box.map50  # map50\n",
    "metrics.box.map75  # map75\n",
    "metrics.box.maps   # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdde73b-9b56-4cea-aebf-a50a4319e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of image paths\n",
    "path = \"\"\n",
    "image_paths = ['bus.jpg', 'car.jpg', 'bike.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c391a05e-ac0e-46f8-9db4-dbd9795618c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on each image and save the results\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    results = model(image_path)  # results list\n",
    "\n",
    "    # Show the results\n",
    "    for r in results:\n",
    "        im_array = r.plot()  # plot a BGR numpy array of predictions\n",
    "        im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "        im.save(f'results_{i}.jpg')  # save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85326dd1-7e4a-4f5b-919a-ed7cf837f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287cad0b-06c0-493a-8222-c4395afaaf49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
